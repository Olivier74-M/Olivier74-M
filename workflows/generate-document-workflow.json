{
  "name": "Bracework – Generate Document (AI Scribe)",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "generate-document",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        -600,
        300
      ],
      "id": "webhook-trigger",
      "name": "Webhook – Generate Document",
      "webhookId": "generate-doc-webhook"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{$env.SUPABASE_URL}}/rest/v1/prompt_templates",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "template_key",
              "value": "=eq.{{$json.document_type}}"
            },
            {
              "name": "select",
              "value": "*"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "apikey",
              "value": "={{$env.SUPABASE_SERVICE_KEY}}"
            },
            {
              "name": "Authorization",
              "value": "=Bearer {{$env.SUPABASE_SERVICE_KEY}}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -400,
        300
      ],
      "id": "fetch-prompt-template",
      "name": "Fetch Prompt Template"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{$env.SUPABASE_URL}}/rest/v1/captures",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "job_id",
              "value": "=eq.{{$('Webhook – Generate Document').item.json.job_id}}"
            },
            {
              "name": "select",
              "value": "*"
            },
            {
              "name": "order",
              "value": "created_at.asc"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "apikey",
              "value": "={{$env.SUPABASE_SERVICE_KEY}}"
            },
            {
              "name": "Authorization",
              "value": "=Bearer {{$env.SUPABASE_SERVICE_KEY}}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -200,
        300
      ],
      "id": "fetch-captures",
      "name": "Fetch All Captures for Job"
    },
    {
      "parameters": {
        "jsCode": "// Assemble context from all captures\nconst captures = $input.all();\n\n// Separate by media type\nconst images = captures.filter(c => c.json.media_type === 'image');\nconst audio = captures.filter(c => c.json.media_type === 'audio');\nconst text = captures.filter(c => c.json.media_type === 'text');\n\n// Build image array for GPT-4 Vision\nconst imageData = images.map(img => ({\n  url: img.json.signed_url,\n  analysis: img.json.image_analysis || '',\n  timestamp: img.json.created_at\n}));\n\n// Combine all text context\nconst imageContext = images\n  .map(img => `IMAGE ANALYSIS: ${img.json.image_analysis || 'No analysis available'}`)\n  .join('\\n\\n');\n\nconst audioContext = audio\n  .map(a => `AUDIO TRANSCRIPT: ${a.json.transcript || 'No transcript available'}`)\n  .join('\\n\\n');\n\nconst textContext = text\n  .map(t => `NOTE: ${t.json.content || ''}`)\n  .join('\\n\\n');\n\n// Combine everything\nconst allTextContext = [\n  imageContext,\n  audioContext,\n  textContext\n].filter(Boolean).join('\\n\\n');\n\n// Return assembled context\nreturn [{\n  json: {\n    images: imageData,\n    transcripts: audio.map(a => a.json.transcript).filter(Boolean).join('\\n\\n'),\n    notes: text.map(t => t.json.content).filter(Boolean).join('\\n\\n'),\n    image_count: images.length,\n    audio_count: audio.length,\n    text_count: text.length,\n    all_text_context: allTextContext\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        0,
        300
      ],
      "id": "assemble-context",
      "name": "Assemble Context from Captures"
    },
    {
      "parameters": {
        "jsCode": "// Build GPT-4 Vision prompt with images\nconst template = $('Fetch Prompt Template').item.json[0];\nconst context = $input.item.json;\nconst systemPrompt = template.system_prompt;\n\n// Build user message\nconst userMessageText = `Here's all the information from my site visit:\\n\\n${context.all_text_context}\\n\\n${context.image_count > 0 ? `I've also included ${context.image_count} photos from the site for your review.` : ''}`;\n\n// Build message content array for GPT-4 Vision\nconst userContent = [\n  {\n    type: 'text',\n    text: userMessageText\n  }\n];\n\n// Add images to content array\nif (context.images && context.images.length > 0) {\n  context.images.forEach(img => {\n    if (img.url) {\n      userContent.push({\n        type: 'image_url',\n        image_url: {\n          url: img.url,\n          detail: 'high'  // High detail for technical analysis\n        }\n      });\n    }\n  });\n}\n\n// Build complete messages array\nconst messages = [\n  {\n    role: 'system',\n    content: systemPrompt\n  },\n  {\n    role: 'user',\n    content: userContent\n  }\n];\n\n// Return GPT-4 Vision request\nreturn [{\n  json: {\n    model: 'gpt-4-vision-preview',\n    messages: messages,\n    max_tokens: 4000,\n    temperature: 0.7\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        200,
        300
      ],
      "id": "build-gpt4-prompt",
      "name": "Build GPT-4 Vision Prompt"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{$env.OPENAI_API_KEY}}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": []
        },
        "specifyBody": "json",
        "jsonBody": "={{JSON.stringify($json)}}",
        "options": {
          "timeout": 120000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        400,
        300
      ],
      "id": "call-gpt4-vision",
      "name": "Call GPT-4 Vision API"
    },
    {
      "parameters": {
        "jsCode": "// Extract and parse GPT-4 response\nconst response = $input.item.json;\nconst generatedContent = response.choices[0].message.content;\nconst tokensUsed = response.usage.total_tokens;\n\n// Get template info to check if line items expected\nconst template = $('Fetch Prompt Template').item.json[0];\nconst includesLineItems = template.includes_line_items || false;\n\n// For MVP: Just save full markdown\n// Future: Parse line items from markdown tables or JSON blocks\nconst lineItemsJson = [];\n\nreturn [{\n  json: {\n    markdown: generatedContent,\n    line_items_json: lineItemsJson,\n    tokens_used: tokensUsed,\n    status: 'draft'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        600,
        300
      ],
      "id": "parse-response",
      "name": "Extract & Parse Response"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{$env.SUPABASE_URL}}/rest/v1/documents",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "apikey",
              "value": "={{$env.SUPABASE_SERVICE_KEY}}"
            },
            {
              "name": "Authorization",
              "value": "=Bearer {{$env.SUPABASE_SERVICE_KEY}}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Prefer",
              "value": "return=representation"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"job_id\": \"{{$('Webhook – Generate Document').item.json.job_id}}\",\n  \"markdown\": {{JSON.stringify($json.markdown)}},\n  \"line_items_json\": {{JSON.stringify($json.line_items_json)}},\n  \"status\": \"{{$json.status}}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        800,
        300
      ],
      "id": "save-document",
      "name": "Save Document to Supabase"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": true,\n  \"document_id\": \"{{$json[0].id}}\",\n  \"job_id\": \"{{$('Webhook – Generate Document').item.json.job_id}}\",\n  \"status\": \"Document generated successfully\",\n  \"preview\": {{JSON.stringify($json[0].markdown.substring(0, 200) + '...')}},\n  \"tokens_used\": {{$('Extract & Parse Response').item.json.tokens_used}}\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        1000,
        300
      ],
      "id": "respond-webhook",
      "name": "Respond to Webhook"
    }
  ],
  "connections": {
    "Webhook – Generate Document": {
      "main": [
        [
          {
            "node": "Fetch Prompt Template",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Prompt Template": {
      "main": [
        [
          {
            "node": "Fetch All Captures for Job",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch All Captures for Job": {
      "main": [
        [
          {
            "node": "Assemble Context from Captures",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Assemble Context from Captures": {
      "main": [
        [
          {
            "node": "Build GPT-4 Vision Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build GPT-4 Vision Prompt": {
      "main": [
        [
          {
            "node": "Call GPT-4 Vision API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call GPT-4 Vision API": {
      "main": [
        [
          {
            "node": "Extract & Parse Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract & Parse Response": {
      "main": [
        [
          {
            "node": "Save Document to Supabase",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Document to Supabase": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 1,
  "updatedAt": "2025-01-15T12:00:00.000Z",
  "versionId": "1"
}
